{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write at least 300 words explaining the types of decision trees algorithms and applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los árboles de decisión son una herramienta que de manera esquemática muestran las alternativas disponibles y de las consecuencias posibles de cada una de ellas. El modelo, en forma de árbol, está conformado por nodos que representan los puntos de decisión y las ramas representan las distintas alternativas. La probabilidad de cada evento, P (E), se indica encima de cada rama, las posibilidades de todas las ramas deben sumar 1.0. (Krajewski & Ritzman, 2000, pág. 76).\n",
    "\n",
    "### Tipos de árboles de decisión:\n",
    "\n",
    "•\tÁrbol de clasificación o binario: se usa cuando existen varias alternativas que se han calculado anteriormente para obtener resultados más predecibles. Con este tipo de árbol se establece un proceso binario de categorías y subcategorías (ramas del árbol), gracias a las probabilidades asociadas, se puede predecir un resultado. Se utiliza en probabilidad, estadística y minería de datos.\n",
    "\n",
    "•\tÁrbol de regresión: ayuda a determinar un único resultado ya que se tiene la información necesaria para identificar una ruta óptima. Cuando se realiza la construcción de este árbol, se divide la información en secciones o subgrupos; este tipo de árbol se utiliza principalmente en el cálculo de bienes raíces. \n",
    "\n",
    "•\tÁrbol de mejora: se utiliza cuando se requiere tener un resultado más preciso del proceso de toma de decisiones. La construcción del árbol inicia tomando una sola variable, que debe ser calculada y estructurada para reducir la incertidumbre y los errores. Considerando que se enfoca en minimizar la cantidad de errores, se cuenta con información más precisa. Se usa frecuentemente en contabilidad y matemáticas.\n",
    "\n",
    "•\tÁrbol mixto clasificación-regresión: usado para predecir el resultado de un evento usando factores dependientes, utilizan indicadores que muestren lo que sucedió en el pasado para “predecir” el resultado esperado. \n",
    "\n",
    "•\tÁrbol binomial y trinomial: cada una de las ramas representa en sí un modelo lineal cuya función es recrear el modelo binomial varias veces en el tiempo, suponiendo variabilidad en precios y costos. \n",
    "\n",
    "•\tAgrupamiento de las K-medias: es el menos preciso, y combina factores entre los que se presume que todos los grupos son iguales. Se usa principalmente en el estudio de la genética.\n",
    "\n",
    "En el área de la minería de datos, se utilizan básicamente dos de los diferentes tipos de árboles de decisión anteriormente mencionados: árboles de clasificación donde el resultado permite establecer la clase a la que pertenecen los datos; y los árboles de regresión cuando el resultado predicho se puede considera un número real. Estos árboles tienen similitudes pero también algunas diferencias, tales como el procedimiento utilizado para determinar donde dividir. \n",
    "\n",
    "Hay un denominado aprendizaje basado en árboles de decisión que consiste en la construcción de un árbol de decisión  a partir de tuplas de entrenamiento, etiquetadas con su clase. Un árbol de decisión es similar a una estructura de diagrama de flujo: cada nodo interno denota una prueba en un atributo, cada rama representa el resultado de una pruea, y cada hoja nodo tiene una etiqueta de clase.  Los algoritmos de árboles de decisiones más destacados son:\n",
    "\n",
    "•\tID3 (Iterative Dichotomiser 3)\n",
    "\n",
    "•\tC4.5 (Sucesor de ID3)\n",
    "\n",
    "•\tACR (Árboles de Clasificación y Regresión)\n",
    "\n",
    "•\tCHAID (Detector automático de Chi-cuadrado de interacción). Realiza divisiones de múltiples niveles al calcular los árboles de clasificación.\n",
    "\n",
    "•\tMARS: Extiende los árboles de decisión para manejar mejor datos numéricos.\n",
    "\n",
    "•\tÁrboles de Inferencia Condicional. Enfoque que utiliza pruebas no paramétricas como criterios de división, corregidos para múltiples pruebas para evitar el sobreajuste. Este enfoque se traduce en la selección de un predictor imparcial y no requiere poda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
