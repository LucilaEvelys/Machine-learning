{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E8 - Ensemble Trees Overview\n",
    "Write at least 300 words explaining why ensemble is a succesful strategy in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjuntos de Árboles de decisión \n",
    " \n",
    "Los conjuntos son métodos que combinan árboles de decisión para alcanzar mejores predicciones que las que se puede alcanzar utilizando únicamente un solo árbol de decisión, lo cual permite concluir que se utilizan para crear modelos más poderosos.  Hay muchos modelos de machine learning documentados en la literatura, pero se habla particularmente de dos que han demostrado ser muy efectivos para una amplia gama de conjuntos de datos de clasificación y regresión que utilizan como componentes básicos los algoritmos de árboles de decisión: random forest y gradient boosted decision trees. \n",
    " \n",
    "#### Random forest: \n",
    "\n",
    "Los árboles de decisión tienden a sobrecargar los datos de entrenamiento, razón por la cual el método de random forest es una herramienta que permite abordar este problema. \n",
    "\n",
    "En esencia es una colección de árboles de decisión donde cada uno es diferente a otro, donde cada uno puede hacer una predicción relativamente buena pero que solo se adapte a una parte de los datos. Al construir muchos árboles, se puede disminuir la cantidad de overfitting promediando sus resultados.  La reducción en el overffiting además de conservar el poder predictivo de los árboles puede mostrarse a través de matemáticas rigurosas. Para que esto sea posible, es necesaria la construcción de muchos árboles, en donde cada uno estará realizando un trabajo de predicción \"aceptable” y además deberá ser diferente de los otros árboles. Dentro de un random forest hay dos formas de que los árboles sean aleatorios: seleccionado los puntos en los datos utilizados para construir el árbol y seleccionando las características para cada una de las pruebas divididas. \n",
    "Para la construcción de un modelo se debe decidir el número de árboles a construir (n_estimators random forest de regresión y/o clasificación). \n",
    "\n",
    "Si se quiere construir 10 árboles (independientes uno del otro) se debe tomar una muestra de arranque (bootstrap) de los datos originales (n_samples) y dibujar repetidamente un ejemplo aleatoriamente con reemplazo durante esas n:samples, lo cual creará un conjunto de datos tan grande como el conjunto de datos original, pero con algunos faltantes –aproximadamente un tercio- y algunos puntos repetidos. Ejemplo: si el conjunto de datos original es ['a', 'b', 'c', 'd'], una posible muestra de bootstrap sería ['b', 'd', 'd', 'c']. \n",
    "\n",
    "A continuación, se crea un árbol de decisiones basado en el conjunto de datos recién creado, aunque el algoritmo descrito para el árbol de decisión haya sido modificado: el algoritmo selecciona aleatoriamente un subconjunto de las características y busca la mejor prueba posible que involucre una de esas características. La selección de un subconjunto de características se repite por separado en cada nodo, de modo que cada nodo en un árbol puede tomar una decisión utilizando un subconjunto diferente de las características. \n",
    "\n",
    "Para hacer la predicción por medio de random forest el algoritmo hace una predicción para cada árbol. Para la regresión se promedian los resultados para obtener la predicción final; para la clasificación, se utiliza la estrategia soft voting, cada algoritmo hace una predicción “suave” y entrega una probabilidad a cada salida posible. \n",
    " \n",
    "Dentro de las ventajas de su uso está que no requiere escalar los datos, contrastado con que necesita de un alto consumo del rendimiento de los equipos donde se corra. Suele arrojar una accuracy 97%, una precisión mayor a la de los modelos lineales o de los árboles de decisión sencillos, sin afinar ningún parámetro. \n",
    "\n",
    "#### Gradient boosted regression trees (gradient boosting machines)  \n",
    "\n",
    "El método de los árboles de regresión con gradiente proyectado es otro método conjunto que combina múltiples árboles de decisión para crear un modelo más poderoso. Puede utilizarse tanto para regresión como para clasificación y se centra en que la proyección del gradiente se hace a través de la construcción de árboles en forma serial, donde cada nuevo árbol intenta corregir los errores del anterior. Por defecto, no hay aleatorización en los árboles de regresión y hace una poda previa. Este método utiliza árboles poco profundos (de 1 a 5), lo que reduce el tamaño del modelo en términos de memoria y hace predicciones más rápidas. \n",
    "\n",
    "El objetivo principal de este modelo es la combinación de muchos modelos simples como árboles poco profundos. Cada árbol puede ofrecer buenas predicciones de una parte de los datos por lo que al agregar más árboles se mejora de forma iterativa el rendimiento del modelo. Son más sensibles a la configuración de parámetros que los carboles usados en random forests pero pueden proporcionar una mejor precisión si los parámetros se configuran correctamente.  \n",
    "\n",
    "La poda previa y la cantidad de árboles dentro del modelo permite considerar como parámetro la tasa de aprendizaje, que controla la intensidad con la que cada árbol intenta corregir los errores de los anteriores. A mayor tasa de aprendizaje mayores son las correcciones que puede hacer de los anteriores lo que se traduce en modelos más complejos. Agregar más árboles al conjunto, aumentando n_estimadores, también aumenta la complejidad del modelo, ya que el modelo tiene más posibilidades de corregir errores en el conjunto de entrenamiento. \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
