{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11\n",
    "\n",
    "## Car Price Prediction\n",
    "\n",
    "Predict if the price of a car is low or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/dataTrain_carListings.zip')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.1\n",
    "\n",
    "Estimate a Decision Tree Classifier Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partición del x_train y el x_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de variables\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza un ejemplo tomando la columna Mileage como si fuera la mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hace las particiones a partir de los percentiles\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puntos donde se va a probar la ganancia de partir el árbol en ese punto\n",
    "splits = np.unique(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1998., 2009., 2011., 2013., 2014., 2015., 2016., 2017.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada nodo, establecer el Gini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini, medida de desigualdad. \n",
    "# Qué tan disímiles son las dos clases. Lo importante es calcular cuál es la ganancia de hacer esa partición. \n",
    "# Si da positivo, es una ganancia.\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza un ejemplo ta como se hizo en el notebook de clase para mayor entendimiento. Se escoge la posición 6.\n",
    "k = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.488419737747639"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12564987217113321"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split #vector booleano (si pertenece o no al lado izquierdo)\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    # Gini total antes de partir\n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10990860399601965"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probar cada característica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10): # num_pct entre màs largo mejores resultados pero mas iteraciones se deben hacer para este caso lo está haciendo de 10 en 10.\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features - se debe probar todo\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 51704.54545454545, 0.23348567756020572)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j, split, gain = best_split(X, y, 10)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mileage'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[1] # el split devuelve el resultado de la mejor columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mileage es la mejor característica para abrir el árbol en el primer nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 8368, 4782)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5795437262357415, 0.8378346080305927, 0.1275616896695943)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X, y, level=0 , min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split calcular la mejor partición en esa variable, devuelve la variable, el valor y la ganancia\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) # antes de partirlo\n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction para que nunca vaya a tender a infinito\n",
    "    \n",
    "    # Guarda la información como si fuera un nodo terminal\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=-1)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split # partición \n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    tree['gain']=gain\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se establecen los criterios para la construcción del árbo: ganancia mínima, máxima profundidad y número de percentiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 8810,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 5606,\n",
       "  'gain': -1},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 3204,\n",
       "  'gain': -1}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 8810,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 5606,\n",
       "  'gain': 0.03317687167496233,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.36828644501278773,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 389,\n",
       "   'gain': 0.05908490521197157,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.08,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 98,\n",
       "    'gain': -1},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.46757679180887374,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 291,\n",
       "    'gain': -1}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8743054224947308,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 5217,\n",
       "   'gain': 0.014933378976312917,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.7348484848484849,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1450,\n",
       "    'gain': -1},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.9278323162642611,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 3767,\n",
       "    'gain': -1}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 3204,\n",
       "  'gain': 0.04366470703709979,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03787566899958831,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 2427,\n",
       "   'gain': 0.0044807442426036265,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.007571345369831101,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 1715,\n",
       "    'gain': -1},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11204481792717087,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 712,\n",
       "    'gain': -1}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.38254172015404364,\n",
       "   'level': 2,\n",
       "   'split': [1, 69702.90909090909],\n",
       "   'n_samples': 777,\n",
       "   'gain': 0.040449309391888344,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.4899193548387097,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 494,\n",
       "    'gain': -1},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.19649122807017544,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 283,\n",
       "    'gain': -1}}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción usando x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred=tree_predict(X_test, tree)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from io import StringIO\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = StringIO()\n",
    "#tree.export_graphviz(tree, out_file='tree_grow.dot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso de sklearn para el cálculo del Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8610599078341014\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print ('accuracy:',metrics.accuracy_score(y_pred, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La precisión del árbol de decisión de manera manual para el conjunto de prueba es de 86,1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.2\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers Manually using the code created in the Notebook #13\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3582, 1346, 5218, ..., 5288, 5094, 8043]),\n",
       " array([ 431, 3426, 8463, ..., 8218,  237, 8326]),\n",
       " array([8477, 4773, 5743, ..., 1809,  214, 6910]),\n",
       " array([5885, 1492, 7249, ..., 1834,  137, 7586]),\n",
       " array([ 352, 4574, 5708, ..., 7142, 2081, 7438]),\n",
       " array([2311, 6342, 4124, ..., 8286, 8453, 1222]),\n",
       " array([5003, 7878, 7832, ..., 3522,  407, 3676]),\n",
       " array([6901, 1829, 1437, ..., 8100, 3585,  522]),\n",
       " array([2874, 2197, 2888, ...,  477, 5922, 4068]),\n",
       " array([5547, 7784, 7473, ..., 4908, 6648, 3622])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_estimators = 10\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Se crean las muestras que serán usadas para seleccionar las filas del dataframe\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se compurba el tamaño de la muestra\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy arbol: 0 : 0.8610599078341014\n",
      "accuracy arbol: 1 : 0.8610599078341014\n",
      "accuracy arbol: 2 : 0.8610599078341014\n",
      "accuracy arbol: 3 : 0.8610599078341014\n",
      "accuracy arbol: 4 : 0.8610599078341014\n",
      "accuracy arbol: 5 : 0.8610599078341014\n",
      "accuracy arbol: 6 : 0.8610599078341014\n",
      "accuracy arbol: 7 : 0.8610599078341014\n",
      "accuracy arbol: 8 : 0.8610599078341014\n",
      "accuracy arbol: 9 : 0.8610599078341014\n"
     ]
    }
   ],
   "source": [
    "#Se crea una variable y_pred donde se va a almacenar la predicción de cada árbol\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "\n",
    "#Se crea un ciclo que va a ir por cada muestra para calcular el respectivo árbol, dentro de este mismo ciclo, se calcula \n",
    "#el accuracy para cada árbol\n",
    "for i in range(n_estimators):\n",
    "    treeBagg=tree_grow(X_train.iloc[samples[i]], y_train.iloc[samples[i]], level=0, min_gain=0.001, max_depth=2, num_pct=10)\n",
    "    y_pred_df.iloc[:, i] = tree_predict(X_test,treeBagg)\n",
    "    print ('accuracy arbol:',i,':',metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el accuracy de cada árbol es de 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332784     2.0\n",
       "146436    10.0\n",
       "130476    10.0\n",
       "85618     10.0\n",
       "75474      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.sum(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8608294930875576"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al calcular el accuracy de todo los arboles como uno solo, se observa que este es 0.86 con los 10 árboles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.3\n",
    "\n",
    "Implement the variable max_features on the Decision Tree Classifier created in 11.1.\n",
    "\n",
    "Compare the impact in the results by varing the parameter max_features\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_features(X, y, num_pct=10,max_features=1): # num_pct entre màs largo mejores resultados pero mas iteraciones se deben hacer para este caso lo está haciendo de 10 en 10.\n",
    "        \n",
    "    \n",
    "    #features = range(X.shape[1])\n",
    "    features = np.random.choice(a=X.shape[1], size=max_features,replace=False)\n",
    "    best_split = [0, 0, 0]\n",
    "    order=np.sort(features)\n",
    "    #print(order)\n",
    "    \n",
    "    # For all features - se debe probar todo\n",
    "    for j in order:\n",
    "        #print(j)\n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        for split in splits:\n",
    "            #print(split)\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "                  \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow_features(X, y, level=0 , min_gain=0.001, max_depth=None, num_pct=10, max_feature=1):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Se agrega la opción max_features al best split, porque está función depende directamente de esta\n",
    "    #opción al dividir la data de acuerdo al número de características\n",
    "    j, split, gain = best_split_features(X, y, num_pct, max_feature)\n",
    "    \n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) # antes de partirlo\n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction para que nunca vaya a tender a infinito\n",
    "    \n",
    "    \n",
    "    # Guarda la información como si fuera un nodo terminal\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=-1)\n",
    "    print(tree)\n",
    "    print(j)\n",
    "    print(split)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree\n",
    "    #if max_features > X.shape[1]:\n",
    "    #    return tree\n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split # partición \n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "    tree['gain']=gain\n",
    "    \n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow_features(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct, max_feature=max_feature)\n",
    "    tree['sr'] = tree_grow_features(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct, max_feature=max_feature)\n",
    "\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_pred': 1, 'y_prob': 0.5780753517930095, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "1\n",
      "52187.63636363637\n",
      "{'y_pred': 1, 'y_prob': 0.8391583452211127, 'level': 1, 'split': -1, 'n_samples': 5606, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.36828644501278773, 'level': 2, 'split': -1, 'n_samples': 389, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 1, 'y_prob': 0.8743054224947308, 'level': 2, 'split': -1, 'n_samples': 5217, 'gain': -1}\n",
      "1\n",
      "28003.636363636364\n",
      "{'y_pred': 0, 'y_prob': 0.12133499688084841, 'level': 1, 'split': -1, 'n_samples': 3204, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.03787566899958831, 'level': 2, 'split': -1, 'n_samples': 2427, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 0, 'y_prob': 0.38254172015404364, 'level': 2, 'split': -1, 'n_samples': 777, 'gain': -1}\n",
      "1\n",
      "69702.90909090909\n"
     ]
    }
   ],
   "source": [
    "#treeFeature = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "treeFeature = tree_grow_features(X_train, y_train, level=0, min_gain=0.001, max_depth=2, num_pct=10, max_feature=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred=tree_predict(X_test, treeFeature)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8610599078341014\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:',metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al realizar el cambio del max_feature se observa que el accuracy cambia entre 0.72, cuando solo tiene un feature hasta 0.86 cuando se utilizan 7 o 9 features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.4\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers with `max_features = log(n_features)`\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3582, 1346, 5218, ..., 5288, 5094, 8043]),\n",
       " array([ 431, 3426, 8463, ..., 8218,  237, 8326]),\n",
       " array([8477, 4773, 5743, ..., 1809,  214, 6910]),\n",
       " array([5885, 1492, 7249, ..., 1834,  137, 7586]),\n",
       " array([ 352, 4574, 5708, ..., 7142, 2081, 7438]),\n",
       " array([2311, 6342, 4124, ..., 8286, 8453, 1222]),\n",
       " array([5003, 7878, 7832, ..., 3522,  407, 3676]),\n",
       " array([6901, 1829, 1437, ..., 8100, 3585,  522]),\n",
       " array([2874, 2197, 2888, ...,  477, 5922, 4068]),\n",
       " array([5547, 7784, 7473, ..., 4908, 6648, 3622])]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "n_estimators = 10\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# Se crean las muestras que serán usadas para seleccionar las filas del dataframe\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_pred': 1, 'y_prob': 0.5795506128007263, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.5593714358129515, 'level': 1, 'split': -1, 'n_samples': 7889, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.39822616407982264, 'level': 2, 'split': -1, 'n_samples': 4508, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.7741649423588531, 'level': 2, 'split': -1, 'n_samples': 3381, 'gain': -1}\n",
      "1\n",
      "52407.0\n",
      "{'y_pred': 1, 'y_prob': 0.7518959913326111, 'level': 1, 'split': -1, 'n_samples': 921, 'gain': -1}\n",
      "1\n",
      "62552.909090909096\n",
      "{'y_pred': 1, 'y_prob': 0.8807947019867549, 'level': 2, 'split': -1, 'n_samples': 753, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 0, 'y_prob': 0.17647058823529413, 'level': 2, 'split': -1, 'n_samples': 168, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5795506128007263, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.07711354793066855, 'level': 1, 'split': -1, 'n_samples': 2825, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.06416464891041163, 'level': 2, 'split': -1, 'n_samples': 2476, 'gain': -1}\n",
      "1\n",
      "47081.0\n",
      "{'y_pred': 0, 'y_prob': 0.17094017094017094, 'level': 2, 'split': -1, 'n_samples': 349, 'gain': -1}\n",
      "0\n",
      "2013.0\n",
      "{'y_pred': 1, 'y_prob': 0.8167696676131618, 'level': 1, 'split': -1, 'n_samples': 5985, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.7888324873096447, 'level': 2, 'split': -1, 'n_samples': 2953, 'gain': -1}\n",
      "1\n",
      "47575.09090909091\n",
      "{'y_pred': 1, 'y_prob': 0.8437705998681608, 'level': 2, 'split': -1, 'n_samples': 3032, 'gain': -1}\n",
      "1\n",
      "55984.63636363637\n",
      "{'y_pred': 1, 'y_prob': 0.5786427598729006, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.07977207977207977, 'level': 1, 'split': -1, 'n_samples': 2806, 'gain': -1}\n",
      "6\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.09007506255212677, 'level': 2, 'split': -1, 'n_samples': 2396, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 0, 'y_prob': 0.021844660194174758, 'level': 2, 'split': -1, 'n_samples': 410, 'gain': -1}\n",
      "1\n",
      "47633.27272727273\n",
      "{'y_pred': 1, 'y_prob': 0.8118548118548119, 'level': 1, 'split': -1, 'n_samples': 6004, 'gain': -1}\n",
      "1\n",
      "57421.909090909096\n",
      "{'y_pred': 1, 'y_prob': 0.8624542124542125, 'level': 2, 'split': -1, 'n_samples': 5458, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.30656934306569344, 'level': 2, 'split': -1, 'n_samples': 546, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5786427598729006, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "1\n",
      "52166.90909090909\n",
      "{'y_pred': 1, 'y_prob': 0.8379101283880172, 'level': 1, 'split': -1, 'n_samples': 5606, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.3155080213903743, 'level': 2, 'split': -1, 'n_samples': 372, 'gain': -1}\n",
      "1\n",
      "35564.818181818184\n",
      "{'y_pred': 1, 'y_prob': 0.8750954927425516, 'level': 2, 'split': -1, 'n_samples': 5234, 'gain': -1}\n",
      "0\n",
      "2015.0\n",
      "{'y_pred': 0, 'y_prob': 0.12507797878976917, 'level': 1, 'split': -1, 'n_samples': 3204, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.043924466338259444, 'level': 2, 'split': -1, 'n_samples': 2434, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 0, 'y_prob': 0.38212435233160624, 'level': 2, 'split': -1, 'n_samples': 770, 'gain': -1}\n",
      "1\n",
      "61895.0\n",
      "{'y_pred': 1, 'y_prob': 0.5798910576486609, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.08189033189033189, 'level': 1, 'split': -1, 'n_samples': 2770, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.11644318983768526, 'level': 2, 'split': -1, 'n_samples': 1415, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 0, 'y_prob': 0.04642593957258659, 'level': 2, 'split': -1, 'n_samples': 1355, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.8083416087388282, 'level': 1, 'split': -1, 'n_samples': 6040, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.7774825639322485, 'level': 2, 'split': -1, 'n_samples': 3009, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.8387734915924827, 'level': 2, 'split': -1, 'n_samples': 3031, 'gain': -1}\n",
      "0\n",
      "2016.0\n",
      "{'y_pred': 1, 'y_prob': 0.5798910576486609, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.08189033189033189, 'level': 1, 'split': -1, 'n_samples': 2770, 'gain': -1}\n",
      "1\n",
      "44044.81818181818\n",
      "{'y_pred': 0, 'y_prob': 0.42913385826771655, 'level': 2, 'split': -1, 'n_samples': 252, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.04722222222222222, 'level': 2, 'split': -1, 'n_samples': 2518, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 1, 'y_prob': 0.8083416087388282, 'level': 1, 'split': -1, 'n_samples': 6040, 'gain': -1}\n",
      "0\n",
      "2015.0\n",
      "{'y_pred': 1, 'y_prob': 0.623403168114461, 'level': 2, 'split': -1, 'n_samples': 1955, 'gain': -1}\n",
      "6\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.8967457793002203, 'level': 2, 'split': -1, 'n_samples': 4085, 'gain': -1}\n",
      "1\n",
      "50437.0\n",
      "{'y_pred': 1, 'y_prob': 0.5709260099863822, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5709260099863822, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.08195568061906437, 'level': 1, 'split': -1, 'n_samples': 2841, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.06645569620253164, 'level': 2, 'split': -1, 'n_samples': 2526, 'gain': -1}\n",
      "1\n",
      "60236.27272727273\n",
      "{'y_pred': 0, 'y_prob': 0.2082018927444795, 'level': 2, 'split': -1, 'n_samples': 315, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.8037179701892481, 'level': 1, 'split': -1, 'n_samples': 5969, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.7893317927979973, 'level': 2, 'split': -1, 'n_samples': 5191, 'gain': -1}\n",
      "1\n",
      "48462.0\n",
      "{'y_pred': 1, 'y_prob': 0.8987179487179487, 'level': 2, 'split': -1, 'n_samples': 778, 'gain': -1}\n",
      "1\n",
      "66221.81818181818\n",
      "{'y_pred': 1, 'y_prob': 0.5802315024965955, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5802315024965955, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.6789225589225589, 'level': 1, 'split': -1, 'n_samples': 7423, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.12534626038781163, 'level': 2, 'split': -1, 'n_samples': 1442, 'gain': -1}\n",
      "1\n",
      "51254.0\n",
      "{'y_pred': 1, 'y_prob': 0.8124686612067524, 'level': 2, 'split': -1, 'n_samples': 5981, 'gain': -1}\n",
      "1\n",
      "56726.27272727277\n",
      "{'y_pred': 0, 'y_prob': 0.05255579553635709, 'level': 1, 'split': -1, 'n_samples': 1387, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 0, 'y_prob': 0.01364522417153996, 'level': 2, 'split': -1, 'n_samples': 1024, 'gain': -1}\n",
      "1\n",
      "93792.00000000001\n",
      "{'y_pred': 0, 'y_prob': 0.1643835616438356, 'level': 2, 'split': -1, 'n_samples': 363, 'gain': -1}\n",
      "1\n",
      "48644.27272727272\n",
      "{'y_pred': 1, 'y_prob': 0.580458465728552, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.5568413021363174, 'level': 1, 'split': -1, 'n_samples': 7862, 'gain': -1}\n",
      "1\n",
      "53549.0\n",
      "{'y_pred': 1, 'y_prob': 0.8267386091127098, 'level': 2, 'split': -1, 'n_samples': 5002, 'gain': -1}\n",
      "6\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.08490566037735849, 'level': 2, 'split': -1, 'n_samples': 2860, 'gain': -1}\n",
      "2\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.7757894736842105, 'level': 1, 'split': -1, 'n_samples': 948, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.580458465728552, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "1\n",
      "52098.90909090909\n",
      "{'y_pred': 1, 'y_prob': 0.8470042796005706, 'level': 1, 'split': -1, 'n_samples': 5606, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.372972972972973, 'level': 2, 'split': -1, 'n_samples': 368, 'gain': -1}\n",
      "1\n",
      "39975.545454545456\n",
      "{'y_pred': 1, 'y_prob': 0.8803435114503817, 'level': 2, 'split': -1, 'n_samples': 5238, 'gain': -1}\n",
      "0\n",
      "2015.0\n",
      "{'y_pred': 0, 'y_prob': 0.1141609482220836, 'level': 1, 'split': -1, 'n_samples': 3204, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.17198764160659114, 'level': 2, 'split': -1, 'n_samples': 1940, 'gain': -1}\n",
      "1\n",
      "69807.18181818182\n",
      "{'y_pred': 0, 'y_prob': 0.026066350710900472, 'level': 2, 'split': -1, 'n_samples': 1264, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5828415796640944, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.5581306507067363, 'level': 1, 'split': -1, 'n_samples': 7851, 'gain': -1}\n",
      "1\n",
      "52702.36363636363\n",
      "{'y_pred': 1, 'y_prob': 0.8201280512204882, 'level': 2, 'split': -1, 'n_samples': 4996, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.09975498774938747, 'level': 2, 'split': -1, 'n_samples': 2855, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.7845993756503642, 'level': 1, 'split': -1, 'n_samples': 959, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5828415796640944, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "1\n",
      "51251.54545454547\n",
      "{'y_pred': 1, 'y_prob': 0.8412981455064193, 'level': 1, 'split': -1, 'n_samples': 5606, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.3341121495327103, 'level': 2, 'split': -1, 'n_samples': 426, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.8830567348514087, 'level': 2, 'split': -1, 'n_samples': 5180, 'gain': -1}\n",
      "1\n",
      "28008.0\n",
      "{'y_pred': 0, 'y_prob': 0.13069245165315035, 'level': 1, 'split': -1, 'n_samples': 3204, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.039932744850777635, 'level': 2, 'split': -1, 'n_samples': 2377, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.39203860072376356, 'level': 2, 'split': -1, 'n_samples': 827, 'gain': -1}\n",
      "0\n",
      "2015.0\n",
      "{'y_pred': 1, 'y_prob': 0.5764866091693146, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.6783974011911207, 'level': 1, 'split': -1, 'n_samples': 7386, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 0, 'y_prob': 0.04838709677419355, 'level': 1, 'split': -1, 'n_samples': 1424, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5764866091693146, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.08505425271263563, 'level': 1, 'split': -1, 'n_samples': 2855, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 0, 'y_prob': 0.01037117903930131, 'level': 2, 'split': -1, 'n_samples': 1830, 'gain': -1}\n",
      "1\n",
      "81409.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_pred': 0, 'y_prob': 0.21908471275559882, 'level': 2, 'split': -1, 'n_samples': 1025, 'gain': -1}\n",
      "1\n",
      "51025.0\n",
      "{'y_pred': 1, 'y_prob': 0.8121537686755078, 'level': 1, 'split': -1, 'n_samples': 5955, 'gain': -1}\n",
      "1\n",
      "48409.0\n",
      "{'y_pred': 1, 'y_prob': 0.885901908475272, 'level': 2, 'split': -1, 'n_samples': 4871, 'gain': -1}\n",
      "1\n",
      "30958.0\n",
      "{'y_pred': 0, 'y_prob': 0.48066298342541436, 'level': 2, 'split': -1, 'n_samples': 1084, 'gain': -1}\n",
      "1\n",
      "63502.0\n",
      "{'y_pred': 1, 'y_prob': 0.5752383113935542, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "8\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.5485801604482363, 'level': 1, 'split': -1, 'n_samples': 7851, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.7929240374609782, 'level': 1, 'split': -1, 'n_samples': 959, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.5752383113935542, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "3\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.6826045497888571, 'level': 1, 'split': -1, 'n_samples': 7339, 'gain': -1}\n",
      "1\n",
      "51191.818181818184\n",
      "{'y_pred': 1, 'y_prob': 0.8557782356246488, 'level': 2, 'split': -1, 'n_samples': 5337, 'gain': -1}\n",
      "0\n",
      "2015.0\n",
      "{'y_pred': 0, 'y_prob': 0.22105788423153694, 'level': 2, 'split': -1, 'n_samples': 2002, 'gain': -1}\n",
      "1\n",
      "72073.0\n",
      "{'y_pred': 0, 'y_prob': 0.04005431093007468, 'level': 1, 'split': -1, 'n_samples': 1471, 'gain': -1}\n",
      "0\n",
      "2012.0\n",
      "{'y_pred': 0, 'y_prob': 0.008071748878923767, 'level': 2, 'split': -1, 'n_samples': 1113, 'gain': -1}\n",
      "1\n",
      "69161.54545454546\n",
      "{'y_pred': 0, 'y_prob': 0.14166666666666666, 'level': 2, 'split': -1, 'n_samples': 358, 'gain': -1}\n",
      "1\n",
      "49167.09090909091\n",
      "{'y_pred': 1, 'y_prob': 0.581593281888334, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "6\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.5636363636363636, 'level': 1, 'split': -1, 'n_samples': 6763, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.0982940698619009, 'level': 2, 'split': -1, 'n_samples': 2460, 'gain': -1}\n",
      "7\n",
      "1.0\n",
      "{'y_pred': 1, 'y_prob': 0.829732868757259, 'level': 2, 'split': -1, 'n_samples': 4303, 'gain': -1}\n",
      "1\n",
      "60299.27272727275\n",
      "{'y_pred': 1, 'y_prob': 0.6408003904343582, 'level': 1, 'split': -1, 'n_samples': 2047, 'gain': -1}\n",
      "0\n",
      "0\n",
      "{'y_pred': 1, 'y_prob': 0.581593281888334, 'level': 0, 'split': -1, 'n_samples': 8810, 'gain': -1}\n",
      "1\n",
      "51690.63636363637\n",
      "{'y_pred': 1, 'y_prob': 0.8411198288159771, 'level': 1, 'split': -1, 'n_samples': 5606, 'gain': -1}\n",
      "1\n",
      "35894.81818181818\n",
      "{'y_pred': 1, 'y_prob': 0.9156626506024096, 'level': 2, 'split': -1, 'n_samples': 3567, 'gain': -1}\n",
      "1\n",
      "24503.0\n",
      "{'y_pred': 1, 'y_prob': 0.7104360607545321, 'level': 2, 'split': -1, 'n_samples': 2039, 'gain': -1}\n",
      "6\n",
      "1.0\n",
      "{'y_pred': 0, 'y_prob': 0.12757330006238304, 'level': 1, 'split': -1, 'n_samples': 3204, 'gain': -1}\n",
      "0\n",
      "2014.0\n",
      "{'y_pred': 0, 'y_prob': 0.04210956663941128, 'level': 2, 'split': -1, 'n_samples': 2444, 'gain': -1}\n",
      "1\n",
      "69013.0\n",
      "{'y_pred': 0, 'y_prob': 0.40288713910761154, 'level': 2, 'split': -1, 'n_samples': 760, 'gain': -1}\n",
      "0\n",
      "2015.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#Se crea una variable y_pred donde se va a almacenar la predicción de cada árbol con log(n_feature)\n",
    "y_pred_df_log = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "#Se crea una variable y_pred donde se va a almacenar la predicción de cada árbol con log(n_feature)\n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "\n",
    "#Número de features a usar\n",
    "n_feature=5\n",
    "\n",
    "#Se crea un ciclo que va a ir por cada muestra para calcular el respectivo árbol, dentro de este mismo ciclo, se calcula \n",
    "#el accuracy para cada árbol\n",
    "for i in range(n_estimators):\n",
    "    treeBagglog=tree_grow_features(X_train.iloc[samples[i]], y_train.iloc[samples[i]], level=0, min_gain=0.001, max_depth=2, num_pct=10,max_feature=int(math.log(n_feature)))\n",
    "    y_pred_df_log.iloc[:, i] = tree_predict(X_test,treeBagglog)\n",
    "    treeBagg=tree_grow_features(X_train.iloc[samples[i]], y_train.iloc[samples[i]], level=0, min_gain=0.001, max_depth=2, num_pct=10,max_feature=n_feature)\n",
    "    y_pred_df_log.iloc[:, i] = tree_predict(X_test,treeBagglog)\n",
    "    y_pred_df.iloc[:, i] = tree_predict(X_test,treeBagg)\n",
    "    #print ('accuracy arbol:',i,':',metrics.accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332784     1.0\n",
       "146436    10.0\n",
       "130476    10.0\n",
       "85618     10.0\n",
       "75474      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.sum(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332784     5.0\n",
       "146436    10.0\n",
       "130476    10.0\n",
       "85618     10.0\n",
       "75474      3.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df_log.sum(axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8610599078341014"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7592165898617511"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = (y_pred_df_log.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "metrics.accuracy_score(y_pred1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los bagged trees con el max_features como el log del número de características se  observa que el accuracy disminuye significativamente si se compara con el max_feature sin realizarle ningún calculo. Por ejemplo con 7 como max_features, se obtiene que cuando se usa log(7) el resultado del accuracy es 0.75, mientras que para max_feature=7 es 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.5\n",
    "\n",
    "Using sklearn, train a RandomForestClassifier\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8451612903225807\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:',metrics.accuracy_score(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 11.6\n",
    "\n",
    "Find the best parameters of the RandomForestClassifier (max_depth, max_features, n_estimators)\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10.000000\n",
       "mean      0.838325\n",
       "std       0.011536\n",
       "min       0.824201\n",
       "25%       0.828897\n",
       "50%       0.836502\n",
       "75%       0.844706\n",
       "max       0.860076\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "pd.Series(cross_val_score(clf, X, y, cv=10)).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por medio de iteraciones se realiza el cálculo del accuracy para distintos estimdores, donde se selecciona el que obtiene una mayor precisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of values to try for n_estimators\n",
    "estimator_range = range(10, 310, 10)\n",
    "\n",
    "# list to store the average Accuracy for each value of n_estimators\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of n_estimators (WARNING: SLOW!)\n",
    "for estimator in estimator_range:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(estimator_range, accuracy_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este caso se selecciona el número de estimadores en 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del n_estimators calculado anteriormente, ahora con un ciclo se procede a calcular cual debe ser el número de features del que se obtiene el mejor accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = range(1, X.shape[1]+1)\n",
    "\n",
    "# list to store the average Accuracy for each value of max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    clf = RandomForestClassifier(n_estimators=25, max_features=feature, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean()) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en el gráfico anterior el mejor accuracy se obtiene para un número de features igual a 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 5)\n"
     ]
    }
   ],
   "source": [
    "# list of values to try for max_depth\n",
    "depth_range = range(1, 5, 1)\n",
    "print(depth_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_depth\n",
    "depth_range = range(1, 10, 1)\n",
    "\n",
    "# list to store the average Accuracy for each value of max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for depth in depth_range:\n",
    "    clf = RandomForestClassifier(n_estimators=25, max_features=9,max_depth=depth, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=5,error_score=np.nan, scoring='accuracy').mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VOXZ//HPlY1AgLCFfd9BRZaIC+6IRbQqdgOX1taKPq22tbZq+2hrbX992j7Vtk+1tmrVilupSsWqILjVBZWwQ9gCKCRsAWQJkP36/TEnOo2BDCSTM0m+79drXjPnzH3OXEdJvjn3feY+5u6IiIgcq6SwCxARkcZNQSIiInWiIBERkTpRkIiISJ0oSEREpE4UJCIiUidxDRIzm2hma8wsz8xuq+H93mb2upktNrNlZjYpWJ9qZn8zs+VmtsrMfhS1zYfB+iVmlhPP+kVEpHYp8dqxmSUD9wETgHxggZnNcvfcqGa3AzPc/X4zGw68BPQFvgS0cPcTzKwVkGtmT7n7h8F257j7znjVLiIisYvnGclYIM/dN7h7KfA0cEm1Ng60DV5nAlui1meYWQrQEigF9sWxVhEROUZxOyMBegCbo5bzgZOrtbkTeMXMbgQygPOC9c8QCZ2tQCvgJnffHbznwTYO/MXdH6itkE6dOnnfvn2P8TBERJqnhQsX7nT3rNraxTNIrIZ11edjmQo86u53m9mpwHQzO57I2UwF0B1oD7xlZvPcfQMwzt23mFlnYK6ZrXb3f3/mw82mAdMAevfuTU6OhlNERI6GmX0US7t4dm3lA72ilnvyaddVlWuAGQDuPh9IBzoBlwOz3b3M3XcA7wDZQbstwfMOYCaR0PkMd3/A3bPdPTsrq9ZAFRGRYxTPIFkADDKzfmaWBkwBZlVrswkYD2Bmw4gESWGw/lyLyABOAVabWYaZtQnaZwDnAyvieAwiIlKLuHVtuXu5md0AzAGSgYfdfaWZ3QXkuPss4GbgQTO7iUi319Xu7mZ2H/AIkZAw4BF3X2Zm/YGZZlZV+5PuPjtexyAiIrWz5jCNfHZ2tmuMRETk6JjZQnfPrq2dvtkuIiJ1oiAREZE6UZCIiEidxPN7JCLSiBSXVfDRroNsKCwiKck4a3AW6anJYZcljYCCRKQZcXcK95ewvvAA6wuL2FB4gA07I8/5Hx+kMuramzbpKVx4Qjcmj+rBSX07kJRU03eMRRQkIk1ScVkFG3ceiARFYVEkNILlopLyT9qlpybRv1NrRvTM5NJRPRiQlcGArNZ8fLCUmYsLmLV0C08v2EzP9i2ZPKoHk0f1oH9W6xCPTBKRLv8VaaTcne37Sj4JivWFB4KwKKJgzyGif7S7Z6bTP6s1/YOg6J+VQf+s1nRrm37EM42DpeXMWbmN5xYV8E7eTiodTuzVjstG9eDzJ3anQ0ZaAxyphCXWy38VJCIJ7lBpxSfdT1VdUesLi9hYeIADpRWftGuVlky/Tv8ZFAOyMujXKYNWaXXvfNi+r5jnlxTw3KICVm/bT0qScfaQzlw2ugfnDu2s8ZQmSEESRUEiic7d2bq3+NOg2PFpV1TBnkP/0bZHu5b/cWZR9dy1bTrBrA9xt2rrPmYuLuCfiwvYsb+EtukpXDiiO5eN7kF2n/YNVofEl4IkioJEEtH89bt48oNNbAgGvQ+VfXp2kZGW/NmuqE6t6dcpg5ZpifOXf0Wl807eTmYuLmD2im0cKqugV4eWTB7Zg8mje9KvU0bYJUodKEiiKEgk0eRu2ccX7n+XjBbJDO+eyYCqrqhOkecubVs0ur/qD5SUM3vFNmYuLuCd9Ttxh1G9I+MpF43oTnuNpzQ6CpIoChJJJLuKSrj43neoqHRm3TCOzm3Twy6p3m3de4jnl2xh5qIC1mzfT2qycU4wnnLO0M60SEmcsyo5PAVJFAWJJIqyikqufOh9Fm/ewz+uO5UTe7ULu6S4cndyt+5j5qICnl+6hcL9JWS2TOXCEd34wugejO6t8ZREpiCJoiCRRHHHP1cw/b2P+N1XTmTyqJ5hl9OgyisqeTsYT5mzchvFZZX06diKS0f24LLRPejTUeMpiUZBEkVBIongyfc38eOZy5l2Zn9+PGlY2OWEqqiknJeXb2Xm4gLmb9iFO4zp057Jo3pw0YhutGul8ZREoCCJoiCRsH2wcTeXP/ge4wZ24uGrTyJZ0418YsueyHjKc4vyWbejiLTkJM4d2pnJo3twzpDOpKVobtmwKEiiKEgkTAV7DnHxH98ms2UqM789jsyWqWGXlJDcnZVb9vHcogJmLS1gZ1Ep7VqlctGIbkwe1ZPRvdtpPKWBKUiiKEgkLIdKK/jin99l066DzPz2OAZ21jxVsSivqOStvJ08t6iAV1Zuo6S8kr4dW3Hu0C60b5VKm/QU2qSn0jo9hTbpKbRNT6V1i5RP1usspn7EGiSatFEkTtydHz6zlNyt+3j4aycpRI5CSnIS5wzpzDlDOrO/uIyXV2zjuUX5PPH+R5SUV9a6fVpKEm2rwuaTgPl0uW21IKppfUZass6AYqQgEYmTP72xnn8t28qtE4dyztDOYZfTaLVJT+XL2b34cnYvAErLKykqKWd/cRn7i8uDR9knz5H3ytlXXP4f7XbtPPjJ66LScmrrjEkyghBK/UwQVb2uWt8yNXFDZ/KoHnEfk1OQiMTBvNzt/PaVNVx8YneuP6t/2OU0KWkpSXRISavTzMOVlc6B0kjgVIXNvuJyiqoFU1FJOfuqXheXs2N/MesLP21XWlH72VHYLhrRjeSk+H4BVEEiUs/yduzne39fwnHd2/LrL4xI2L9Um7OkJAvOKOp24UNxWQVFJeUcipqFOdGkJcd/vEhBIlKP9h4s45t/yyE9NZkHrspOqAkWpf6lpyZr+nwgrlFlZhPNbI2Z5ZnZbTW839vMXjezxWa2zMwmBetTzexvZrbczFaZ2Y9i3adIWMorKrnhqUUU7DnEn68cTfd2LcMuSaRBxC1IzCwZuA+4ABgOTDWz4dWa3Q7McPdRwBTgT8H6LwEt3P0EYAxwnZn1jXGfIqH41cureWvdTn5+yfFk9+0QdjkiDSaeZyRjgTx33+DupcDTwCXV2jjQNnidCWyJWp9hZilAS6AU2BfjPkUa3LML83no7Y187dQ+TBnbO+xyRBpUPIOkB7A5ajk/WBftTuBKM8sHXgJuDNY/AxwAtgKbgN+6++4Y9ynSoJZs3sOPZi7n1P4duf0inSBL8xPPIKnpUpXqV25PBR51957AJGC6mSUROfOoALoD/YCbzax/jPuMfLjZNDPLMbOcwsLCYz0GkSPavq+YaY/l0KVtC/50xWhSG+AKGZFEE89/9flAr6jlnnzadVXlGmAGgLvPB9KBTsDlwGx3L3P3HcA7QHaM+yTY3wPunu3u2VlZWfVwOCL/qbisguumL6SopJwHv5qtOwBKsxXPIFkADDKzfmaWRmQwfVa1NpuA8QBmNoxIkBQG68+1iAzgFGB1jPsUiTt3579nrmDJ5j3c8+WRDO3atvaNRJqouAWJu5cDNwBzgFVErs5aaWZ3mdnFQbObgWvNbCnwFHC1R2aRvA9oDawgEh6PuPuyw+0zXscgcjh/fXsjzy7K53vnDWLi8V3DLkckVJr9V+QovbWukK89/AEThnfh/ivGkKR7i0gTFevsvxoZFDkKH+48wA1PLmZwlzbc8+WRChERFCQiMdtfXMY3H8vBDB78ajYZLTTDkAhori2RmFRWOjf9fQkbdx5g+jfG0qtDq7BLEkkYOiMRicE9c9cyb9UOfnLRcE4b2CnsckQSioJEpBb/WraFe1/PY8pJvfjqqX3CLkck4ShIRI5g5Za9/OAfS8nu0567Ljle9xYRqYGCROQwdhaVMO2xhbRvlcb9V44hLUU/LiI10WC7SA1Kyyv51uOL2FlUwjPXn0ZWmxZhlySSsBQkIjX42Qsr+eDD3fxhykhO6JkZdjkiCU3n6iLVPP7eRzzx/iauP2sAl4zUXQpEaqMgEYny3oZd3DlrJecO7cwPPzck7HJEGgUFiUhg8+6DfOuJRfTu2IrfTxlJsqY/EYmJgkQEOFhazrTpCymrqOShr2bTNj017JJEGg0FiTR77s4P/7GMNdv28cepo+if1TrskkQaFQWJNHv3vpbHi8u3ctsFQzl7SOewyxFpdBQk0qy9snIbd89dy+RRPbj2jP5hlyPSKClIpNlau30/N/19CSN6ZvI/l52g6U9EjpGCRJqlPQdLufaxHFq1SOGBq7JJT00OuySRRktBIs1OeUUlNzy5mK17ivnzlWPompkedkkijZqmSJFm55cvrebtvJ385osjGNOnfdjliDR6OiORZuUfOZt5+J2NfH1cX76c3SvsckSaBAWJNBuLNn3Mf89cwbiBHfnvScPCLkekyVCQSLOwbW8x101fSNfMdO6dOpqUZP3TF6kvcf1pMrOJZrbGzPLM7LYa3u9tZq+b2WIzW2Zmk4L1V5jZkqhHpZmNDN57I9hn1Xv6BpkcUXFZBddNz+FgSTkPfS2b9hlpYZck0qTEbbDdzJKB+4AJQD6wwMxmuXtuVLPbgRnufr+ZDQdeAvq6+xPAE8F+TgCed/clUdtd4e458apdGj93Z31hEXNzd/DC0i3kbt3HA1eNYXCXNmGXJtLkxPOqrbFAnrtvADCzp4FLgOggcaBt8DoT2FLDfqYCT8WxTmkiKiqdhR99zNzcbcxbtYONOw8AcEKPTO7+0omcf1zXkCsUaZriGSQ9gM1Ry/nAydXa3Am8YmY3AhnAeTXs5ytEAijaI2ZWATwL/MLdvV4qlkbnQEk5b60rZG7uDl5bvZ2PD5aRmmycOqAT3zi9H+cN60y3zJZhlynSpMUzSGqab6L6L/ypwKPufreZnQpMN7Pj3b0SwMxOBg66+4qoba5w9wIza0MkSK4CHvvMh5tNA6YB9O7du+5HIwljx75i5q3awdzcbbyzfhel5ZVktkzl3KGdOW9YF84c3Ik2mgZepMHEM0jygegL9Xvy2a6ra4CJAO4+38zSgU7AjuD9KVTr1nL3guB5v5k9SaQL7TNB4u4PAA8AZGdn64ylEXN31m4vYt6q7bySu52lm/cA0KtDS648uQ8Thnchu297UnUllkgo4hkkC4BBZtYPKCASCpdXa7MJGA88ambDgHSgEMDMkoAvAWdWNTazFKCdu+80s1TgImBeHI9BQlJeUckHH+5mXu4O5q3azqbdBwE4sVc7fnD+YCYM78rgLq010aJIAohbkLh7uZndAMwBkoGH3X2lmd0F5Lj7LOBm4EEzu4lIt9fVUeMdZwL5VYP1gRbAnCBEkomEyIPxOgZpWEUl5by5ppB5q7bz2uod7D1URlpKEuMGdOT6swYwflhnurTVvFgiicaawzh1dna25+ToauFEtHXvoWC8Yzvvrd9FaUUl7Vulcu7QLkwY3pkzBmWR0UJTwomEwcwWunt2be30EyoNyt1ZtXU/c3O3M2/VdpYX7AWgb8dWfO20PkwY3pXRvdvpm+cijYiCROKurKKS9zfsZt6q7czN3U7BnkOYwahe7bh14lAmDO/MgCyNd4g0VgoSiYu9h8p4c20hc3O388aaHewvLic9NYnTB2bxnfEDOXdoF7LatAi7TBGpBwoSqTe7D5Qya0kB81bt4L0NuyivdDpmpHHB8V2ZMLwrpw/sRMs03YlQpKlRkEi9qKh0Ln/wPVZv28+ArAy+eUZ/JgzvzMhe7UlOUpeVSFOmIJF68dyifFZv28/vvnIik0f1DLscEWlAujRG6qy4rILfzV3LiT0zuXRkj7DLEZEGpiCROps+/yO27C3m1guG6sorkWZIQSJ1svdQGfe+nsdZg7M4bUCnsMsRkRAoSKRO/vzmevYeKuOWiUPCLkVEQqIgkWO2bW8xj7yzkUtHdue47plhlyMiIVGQyDH7w6trqah0bj5fZyMizZmCRI5J3o4iZuTkc8XJfejVoVXY5YhIiBQkckx+O2cNLVOTufHcgWGXIiIhU5DIUVu06WNmr9zGtWf0p2NrzZcl0twpSOSouDu/enk1nVqn8c0z+oVdjogkAAWJHJU31hTywcbdfHf8IN1wSkQABYkchYpK59ezV9OnYyumjO0ddjkikiBqDRIzu8HM2jdEMZLYnl9SwOpt+/nB+UNI1R0MRSQQy2+DrsACM5thZhNNkyk1SyXlFdz9ylpO6JHJhSd0C7scEUkgtQaJu98ODAL+ClwNrDOzX5rZgDjXJgnk8fc2UbDnELdOHEqS7i8iIlFi6p9wdwe2BY9yoD3wjJn9Jo61SYLYV1zGva+t44xBnTh9kCZmFJH/VOtlN2b2HeBrwE7gIeCH7l5mZknAOuCW+JYoYXvgzQ18fLCMWycODbsUEUlAsVy/2Qm4zN0/il7p7pVmdlF8ypJEsWNfMX99eyOfP7E7x/fQxIwi8lmxdG29BOyuWjCzNmZ2MoC7rzrShsHg/BozyzOz22p4v7eZvW5mi81smZlNCtZfYWZLoh6VZjYyeG+MmS0P9vl/GvyPrz+8uo6yikp+cP7gsEsRkQQVS5DcDxRFLR8I1h2RmSUD9wEXAMOBqWY2vFqz24EZ7j4KmAL8CcDdn3D3ke4+ErgK+NDdl0TVM43IBQCDgIkxHIMcgw2FRTy9YDOXn9ybPh0zwi5HRBJULEFiwWA7EOnSIrYusbFAnrtvcPdS4GngkmptHGgbvM4EttSwn6nAUwBm1g1o6+7zg5oeAy6NoRY5Bne/spYWKUnceO6gsEsRkQQWS5BsMLPvmFlq8PgusCGG7XoAm6OW84N10e4ErjSzfCJdaDfWsJ+vEARJsH1+LfsEwMymmVmOmeUUFhbGUK5EW7p5Dy8u38q1Z/Qnq40mZhSRw4slSK4HTgMKiPziPplI11Jtahq78GrLU4FH3b0nMAmYHlwNFtlBZCzmoLuvOIp9Rla6P+Du2e6enZWVFUO5UqVqYsaOGWlce2b/sMsRkQRXaxeVu+8gMn5xtPKBXlHLPfls19U1BGMc7j7fzNKJXCW2I3h/Cp+ejVTts2ct+5Q6+ve6nczfsIs7Pz+c1pqYUURqEcv3SNKJ/MI/DkivWu/u36hl0wXAIDPrR+RsZgpwebU2m4DxwKNmNizYf2HwuUnAl4Azoz5zq5ntN7NTgPeBrwJ/rO0YJHaVlZGzkV4dWnL5yX3CLkdEGoFYuramE5lv63PAm0TOAvbXtpG7lwM3AHOAVUSuzlppZneZ2cVBs5uBa81sKZEzj6ujBvbPBPLdvfp4zH8R+WJkHrAeeDmGY5AYvbBsC6u27uMH5w8hLUUTM4pI7SzqgqyaG5gtdvdRZrbM3UeYWSowx93PbZgS6y47O9tzcnLCLiPhlZRXMP7uN2mbnsq/bjxdc2qJNHNmttDds2trF8ufnGXB8x4zO57IZbp961CbJKgn399E/seHuPUCTcwoIrGLZST1geB+JLcDs4DWwB1xrUoa3P7iMv74Wh6nDejImZqYUUSOwhGDJBjw3ufuHwP/BnQtaBP14Fsb2X2glFsnDkWzzojI0Thi11bwLfYbGqgWCUnh/hIeemsDF57QjRN7tQu7HBFpZGIZI5lrZj8ws15m1qHqEffKpMH88bV1lJRX8oPPDQm7FBFphGIZI6n6vsi3o9Y56uZqEj7ceYAn39/E1LG96NdJEzOKyNGL5Zvt/RqiEAnH3XPXkpqcxHfGa2JGETk2sXyz/as1rXf3x+q/HGlIy/P38sLSLdx47kA6t0mvfQMRkRrE0rV1UtTrdCJTmiwiMoW7NGK/nr2a9q1SmaaJGUWkDmLp2vqPqd3NLJPItCnSiL21rpC383Zyx0XDaZOeGnY5ItKIHctkSgeJ3JlQGqnKSufXs1fTo11Lrjyld9jliEgjF8sYyQt8es+PJCK3zZ0Rz6Ikvl5cvpUVBfu458sn0iIlOexyRKSRi2WM5LdRr8uBj9w9/3CNJbGVllfy21fWMLRrGy4ZWePNJUVEjkosQbIJ2OruxQBm1tLM+rr7h3GtTOLi6QWb+GjXQR75+kkka2JGEakHsYyR/AOojFquCNZJI3OgpJz/e3UdJ/frwNmDdfthEakfsQRJiruXVi0Er9PiV5LEy0NvbWRnUSm3XaCJGUWk/sQSJIVRdzTEzC4BdsavJImHnUUlPPDv9Uw8riujercPuxwRaUJiGSO5HnjCzO4NlvOJ3CtdGpF7X8ujuLySH07UxIwiUr9i+ULieuAUM2tN5Na8td6vXRLLpl0HeeL9j/hydi8GZLUOuxwRaWJq7doys1+aWTt3L3L3/WbW3sx+0RDFSf24Z+4akpOM752n75GKSP2LZYzkAnffU7UQ3C1xUvxKkvq0omAv/1yyhW+M60eXtpqYUUTqXyxBkmxmLaoWzKwl0OII7SWB/GbOGtq1SuW6swaEXYqINFGxDLY/DrxqZo8Ey18H/ha/kqS+vJu3k3+vLeS/Jw0js6UmZhSR+Kj1jMTdfwP8AhhGZJ6t2UCfWHZuZhPNbI2Z5ZnZbTW839vMXjezxWa2zMwmRb03wszmm9lKM1tuZunB+jeCfS4JHp1jPNZmxd351ezVdM9M56pTY/rfJSJyTGI5IwHYRuTb7V8GNgLP1raBmSUD9wETiFwyvMDMZrl7blSz24EZ7n6/mQ0HXgL6mlkKkTOhq9x9qZl1BMqitrvC3XNirL1Zemn5Npbl7+V/vziC9FRNzCgi8XPYIDGzwcAUYCqwC/g7kct/z4lx32OBPHffEOzvaeASIDpIHGgbvM4EtgSvzweWuftSAHffFeNnClBWEZmYcXCX1lw2umfY5YhIE3ekrq3VRO6G+Hl3P93d/0hknq1Y9QA2Ry3nB+ui3QlcaWb5RM5Gqm6iNRhwM5tjZovM7JZq2z0SdGvdYYeZ68PMpplZjpnlFBYWHkXZjd/fF2xm484D3DpxqCZmFJG4O1KQfIFIl9brZvagmY0Hjua3Uk1tvdryVOBRd+9J5JLi6WaWRORM6XTgiuB5cvD5EOnWOgE4I3hcVdOHu/sD7p7t7tlZWc1ngsKDpeX84dV1nNS3PecO1fCRiMTfYYPE3We6+1eAocAbwE1AFzO738zOj2Hf+UCvqOWefNp1VeUagptkuft8IveE7xRs+6a773T3g0TOVkYH7QqC5/3Ak0S60CTw8NsbKdxfookZRaTBxHLV1gF3f8LdLyISBkuAz1yBVYMFwCAz62dmaUTGW2ZVa7OJSPcZZjaMSJAUAnOAEWbWKhh4PwvINbMUM+sUtE8FLgJWxFBLs7D7QCl/fnMD5w/vwpg+HcIuR0SaiViv2gLA3XcDfwketbUtN7MbiIRCMvCwu680s7uAHHefBdwMPGhmNxHp9rra3R342MzuIRJGDrzk7i+aWQYwJwiRZGAe8ODRHENTdt/reRwsLecWTcwoIg3oqILkaLn7S0S6paLX/STqdS4w7jDbPk7kEuDodQeAMfVfaeO3efdBps//iC+N6cXAzm3CLkdEmpFYpkiRRuB3c9diBt+boIkZRaRhKUiagFVb9zFzSQFXj+tLt8yWYZcjIs2MgqQJ+M3s1bRpkcK3zhoYdiki0gwpSBq59zbs4vU1hXzrnIFkttLEjCLS8BQkjZi786uXV9O1bTpXn9Y37HJEpJlSkDRic1ZuY8nmPXx/wmBNzCgioVGQNFLlFZX8Zs4aBnZuzWWjq09hJiLScBQkjdQ/FuazofAAt3xuCCnJ+t8oIuHRb6BG6FBpBb+bu5YxfdozYXiXsMsRkWZOQdIIPfLuRnZoYkYRSRAKkkZm295i7nstj/OGdeakvpqYUUTCpyBpZH7xYi5llc4dFw0PuxQREUBB0qi8k7eTfy3byrfOHkCfjhlhlyMiAihIGo2S8grueH4FfTq24vqzBoRdjojIJ+I6jbzUn4fe2siGwgM8+vWT9OVDEUkoOiNpBDbvPsgfX1vHxOO6cvYQ3YddRBKLgqQRuOtfuRjGTz6vAXYRSTwKkgT36qrtzM3dznfPG0T3drrXiIgkHgVJAisuq+DOF1YysHNrvjGuX9jliIjUSIPtCexPr+exefchnrr2FNJSlPkikpj02ylBbdx5gD+/uYFLR3bn1AEdwy5HROSwFCQJyN356ayVtEhJ4scXDgu7HBGRI1KQJKCXV2zj32sL+f75g+ncJj3sckREjiiuQWJmE81sjZnlmdltNbzf28xeN7PFZrbMzCZFvTfCzOab2UozW25m6cH6McFynpn9nzWx6W8PlJRz1wu5DO/WlqtO6RN2OSIitYpbkJhZMnAfcAEwHJhqZtW/CHE7MMPdRwFTgD8F26YAjwPXu/txwNlAWbDN/cA0YFDwmBivYwjD/726jm37ivn5pcfrhlUi0ijE8zfVWCDP3Te4eynwNHBJtTYOtA1eZwJbgtfnA8vcfSmAu+9y9woz6wa0dff57u7AY8ClcTyGBrV2+37++vZGvpLdizF92oddjohITOIZJD2AzVHL+cG6aHcCV5pZPvAScGOwfjDgZjbHzBaZ2S1R+8yvZZ+Nkrtz+z9X0Do9hVsvGBp2OSIiMYtnkNQ0duHVlqcCj7p7T2ASMN3Mkoh8v+V04IrgebKZjY9xn5EPN5tmZjlmllNYWHisx9Bg/rmkgA827uaWzw2lQ0Za2OWIiMQsnkGSD/SKWu7Jp11XVa4BZgC4+3wgHegUbPumu+9094NEzlZGB+t71rJPgv094O7Z7p6dlZVVD4cTP3sPlfH/XlzNib3aMeWkXrVvICKSQOIZJAuAQWbWz8zSiAymz6rWZhMwHsDMhhEJkkJgDjDCzFoFA+9nAbnuvhXYb2anBFdrfRV4Po7H0CDueWUNuw+U8P8uPZ6kpCZ1EZqINANxmyLF3cvN7AYioZAMPOzuK83sLiDH3WcBNwMPmtlNRLqorg4G0T82s3uIhJEDL7n7i8Gu/wt4FGgJvBw8Gq0VBXuZ/t5HXHlKH47vkRl2OSIiR80iv7ebtuzsbM/JyQm7jM+orHQuu/9d8j8+yKs3n01my9SwSxIR+YSZLXT37Nra6YsKIfp7zmaWbN7DjycNU4iISKOlIAnJ7gOl/Hr2asb268DkUU3iCmYRaaYUJCH5zezV7C9sAzAhAAAMJElEQVQu5+eXHE8Tm+VFRJoZBUkIFm36mKcXbOYb4/oypGubsMsREakTBUkDK6+o5PaZK+jaNp3vnjc47HJEROpMQdLAHn/vI3K37uOOi4bTuoVuUCkijZ+CpAHt2F/M3a+s5YxBnZh0QtewyxERqRcKkgb0Py+tpqS8kp9dfJwG2EWkyVCQNJD563cxc3EB153Vn/5ZrcMuR0Sk3ihIGkBZRSU/eX4FPdu35FtnDwy7HBGReqXR3gbw8NsbWbejiIe+mk3LtOSwyxERqVc6I4mzLXsO8ft56zhvWBfOG94l7HJEROqdgiTOfv6vXBznp5+vfrt6EZGmQUESR2+uLeTlFdu44ZyB9OrQKuxyRETiQkESJ8VlFfz0+RX075TBtWf2D7scEZG40WB7nPzlzQ18uOsg068ZS4sUDbCLSNOlM5I42LTrIH96I48LR3TjjEGJfb94EZG6UpDUM3fnp7NWkJJk3HGhBthFpOlTkNSzV3K38/qaQr533mC6ZqaHXY6ISNwpSOrRwdJy7nohlyFd2nD1uL5hlyMi0iA02F6P7n0tj4I9h5hx3amkJiujRaR50G+7epK3o4gH39rAZaN7MLZfh7DLERFpMAqSeuDu/OT5FaSnJvOjC4aFXY6ISIOKa5CY2UQzW2NmeWZ2Ww3v9zaz181ssZktM7NJwfq+ZnbIzJYEjz9HbfNGsM+q9zrH8xhi8cKyrby7fhe3fG4IWW1ahF2OiEiDitsYiZklA/cBE4B8YIGZzXL33KhmtwMz3P1+MxsOvAT0Dd5b7+4jD7P7K9w9J06lH5X9xWX84l+5nNAjk8tP7hN2OSIiDS6eZyRjgTx33+DupcDTwCXV2jjQNnidCWyJYz1x8ft56ygsKuHnlx5PcpLueigizU88g6QHsDlqOT9YF+1O4EozyydyNnJj1Hv9gi6vN83sjGrbPRJ0a91hId6zdtXWfTz67odMOak3I3u1C6sMEZFQxTNIavoF79WWpwKPuntPYBIw3cySgK1Ab3cfBXwfeNLMqs5crnD3E4AzgsdVNX642TQzyzGznMLCwno4nP9UWenc8c8VZLZM5ZbPDan3/YuINBbxDJJ8oFfUck8+23V1DTADwN3nA+lAJ3cvcfddwfqFwHpgcLBcEDzvB54k0oX2Ge7+gLtnu3t2Vlb9z3f17KJ8cj76mNsmDqV9Rlq9719EpLGIZ5AsAAaZWT8zSwOmALOqtdkEjAcws2FEgqTQzLKCwXrMrD8wCNhgZilm1ilYnwpcBKyI4zHUaM/BUv7n5dWM7t2OL47p2dAfLyKSUOJ21Za7l5vZDcAcIBl42N1XmtldQI67zwJuBh40s5uIdHtd7e5uZmcCd5lZOVABXO/uu80sA5gThEgyMA94MF7HcDj/O2cNew6W8otrTiZJA+wi0szFdYoUd3+JyCB69LqfRL3OBcbVsN2zwLM1rD8AjKn/SmO3dPMenvxgE1ef1pfh3dvWvoGISBOnb7YfhYpK547nV9CpdQtumjA47HJERBKCguQoPPnBJpbl7+X2C4fRNj017HJERBKCgiRGO4tK+N/Zqzm1f0cuPrF72OWIiCQMBUmMfvXyag6VVfDzS48jxO9AiogkHAVJDBZ8uJtnFuZzzen9Gdi5TdjliIgkFAVJLcorKrnjnyvonpnOd8YPDLscEZGEoyCpxaPvfsjqbfv5yeePo1WabigpIlKdguQItu0t5ndz13L2kCw+d1yXsMsREUlICpIj+MWLuZRVOj+7WAPsIiKHoyA5jPKKStKSk/jW2QPo0zEj7HJERBKWOv0PIyU5iXu+MhL36jPfi4hINJ2R1EJdWiIiR6YgERGROlGQiIhInShIRESkThQkIiJSJwoSERGpEwWJiIjUiYJERETqxJrDF+7MrBD46Bg37wTsrMdy6ovqOjqq6+iorqPTVOvq4+5ZtTVqFkFSF2aW4+7ZYddRneo6Oqrr6Kiuo9Pc61LXloiI1ImCRERE6kRBUrsHwi7gMFTX0VFdR0d1HZ1mXZfGSEREpE50RiIiInWiIDkMM3vYzHaY2Yqwa4lmZr3M7HUzW2VmK83su2HXBGBm6Wb2gZktDer6Wdg1VTGzZDNbbGb/CruWaGb2oZktN7MlZpYTdj1VzKydmT1jZquDf2enJkBNQ4L/TlWPfWb2vbDrAjCzm4J/8yvM7CkzSw+7JgAz+25Q08p4/7dS19ZhmNmZQBHwmLsfH3Y9VcysG9DN3ReZWRtgIXCpu+eGXJcBGe5eZGapwNvAd939vTDrAjCz7wPZQFt3vyjseqqY2YdAtrsn1PcPzOxvwFvu/pCZpQGt3H1P2HVVMbNkoAA42d2P9fth9VVLDyL/1oe7+yEzmwG85O6PhlzX8cDTwFigFJgN/Je7r4vH5+mM5DDc/d/A7rDrqM7dt7r7ouD1fmAV0CPcqsAjioLF1OAR+l8pZtYTuBB4KOxaGgMzawucCfwVwN1LEylEAuOB9WGHSJQUoKWZpQCtgC0h1wMwDHjP3Q+6eznwJjA5Xh+mIGnEzKwvMAp4P9xKIoIupCXADmCuuydCXb8HbgEqwy6kBg68YmYLzWxa2MUE+gOFwCNBd+BDZpYRdlHVTAGeCrsIAHcvAH4LbAK2Anvd/ZVwqwJgBXCmmXU0s1bAJKBXvD5MQdJImVlr4Fnge+6+L+x6ANy9wt1HAj2BscHpdWjM7CJgh7svDLOOIxjn7qOBC4BvB92pYUsBRgP3u/so4ABwW7glfSroarsY+EfYtQCYWXvgEqAf0B3IMLMrw60K3H0V8GtgLpFuraVAebw+T0HSCAVjEM8CT7j7c2HXU13QFfIGMDHkUsYBFwdjEU8D55rZ4+GW9Cl33xI87wBmEunPDls+kB91NvkMkWBJFBcAi9x9e9iFBM4DNrp7obuXAc8Bp4VcEwDu/ld3H+3uZxLppo/L+AgoSBqdYFD7r8Aqd78n7HqqmFmWmbULXrck8gO2Osya3P1H7t7T3fsS6Q55zd1D/2sRwMwygoslCLqOzifSHREqd98GbDazIcGq8UCoF3JUM5UE6dYKbAJOMbNWwc/meCLjlqEzs87Bc2/gMuL43y0lXjtu7MzsKeBsoJOZ5QM/dfe/hlsVEPkr+ypgeTAeAfBjd38pxJoAugF/C66oSQJmuHtCXW6bYLoAMyO/e0gBnnT32eGW9IkbgSeCbqQNwNdDrgeAoK9/AnBd2LVUcff3zewZYBGRrqPFJM633J81s45AGfBtd/84Xh+ky39FRKRO1LUlIiJ1oiAREZE6UZCIiEidKEhERKROFCQiIlInChIREakTBYlIggimle90jNtebWbd62NfIkdLQSLSNFxNZK4nkQanIBGpxsz6Bjd1eii4MdATZnaemb1jZuvMbGzweDeYIffdqilFzOz7ZvZw8PqEYPtWh/mcjmb2SrCPvwAW9d6VwY3ClpjZX4IZAzCzIjO728wWmdmrwdQ0XyRyv5UngvYtg93cGLRbbmZD4/nfTJo3BYlIzQYCfwBGAEOBy4HTgR8APyYyj9iZwQy5PwF+GWz3e2CgmU0GHgGuc/eDh/mMnwJvB/uYBfQGMLNhwFeIzA48EqgArgi2ySAyaeFoIveY+Km7PwPkAFe4+0h3PxS03Rm0uz+oWyQuNNeWSM02uvtyADNbCbzq7m5my4G+QCaRucUGEbmvSCqAu1ea2dXAMuAv7v7OET7jTCKT6eHuL5pZ1VxI44ExwIJgLq6WRO7xApH7qvw9eP04kdlmD6fqvYVVnyMSDwoSkZqVRL2ujFquJPJz83PgdXefHNxg7I2o9oOI3KY5ljGLmia7M+Bv7v6jY9y+SlXNFehnXeJIXVsixyaTyH3DITLQDYCZZRLpEjsT6BiMXxzOvwm6rMzsAqB9sP5V4ItR04B3MLM+wXtJQNU+Lydyv3CA/UCbOhyPyDFTkIgcm98A/2Nm7wDJUet/B/zJ3dcC1wC/qgqEGvyMyO1QFxG5H8kmAHfPBW4nchveZUTuctct2OYAcJyZLQTOBe4K1j8K/LnaYLtIg9A08iKNiJkVuXvrsOsQiaYzEhERqROdkYjEmZl9HfhutdXvuPu3w6hHpL4pSEREpE7UtSUiInWiIBERkTpRkIiISJ0oSEREpE4UJCIiUif/Hzr9ILP8cMgSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un max_depth de 6 se obtiene el mejor accuracy, por lo que este es el último parámetro de nuestro árbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=6, max_features=9, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=25, n_jobs=-1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfM = RandomForestClassifier(n_estimators=25, max_features=9, max_depth=6,random_state=1, n_jobs=-1)\n",
    "clfM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame({'feature':, 'importance':clf.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predM=clfM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8783410138248848\n"
     ]
    }
   ],
   "source": [
    "print ('accuracy:',metrics.accuracy_score(y_predM, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa al realizar la búsqueda de los parámetros que mejoran el árbol, se obtuvo un aumento en el accuracy del 4%, por lo que se confirma que si se selecciona de manera adecuada los parámetros se puede mejorar el accuracy para nuestro modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
